{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    # 특정 GPU에 1GB 메모리만 할당하도록 제한\n",
    "    try:\n",
    "        tf.config.experimental.set_visible_devices(gpus[1], 'GPU')\n",
    "        tf.config.experimental.set_virtual_device_configuration(\n",
    "            gpus[1],\n",
    "            [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=7048)])\n",
    "    except RuntimeError as e:\n",
    "    # 프로그램 시작시에 가상 장치가 설정되어야만 합니다\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#이미지 전처리 해서 비교\n",
    "# keras.applications.inception_v3 import InceptionV3 from ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "% matplotlib inline\n",
    "\n",
    "import matplotlib.image as img\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications.xception import Xception\n",
    "from tensorflow.keras.applications import InceptionResNetV2\n",
    "from tensorflow.keras.applications import InceptionV3\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from scipy import stats\n",
    "from PIL import Image \n",
    "from mtcnn import MTCNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_file_path='./data/deepfake/deepfake_model_1113_02.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "callbacks_list = [tf.keras.callbacks.EarlyStopping(monitor='val_acc',  # 검증 정확도 모니터링\n",
    "                                                   patience=3),             # 1 epoch보다 더 길게 정확도 향상되지 않으면 훈련 중지\n",
    "                  \n",
    "                  tf.keras.callbacks.ModelCheckpoint(filepath=save_file_path,\n",
    "                                                     monitor='val_loss',    # 검증 loss 모니터링\n",
    "                                                     save_best_only=True),  # 가장 좋은 모델을 저장\n",
    "                  \n",
    "                  tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss',  # 검증 loss 모니터링\n",
    "                                                      factor=0.1,           # 콜백 호출시 학습률 10배로 줄임\n",
    "                                                      patience=5)]          # 검증손실이 해당 epoch만큼 좋아지지 않으면 콜백 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import mnist\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, Activation, LeakyReLU\n",
    "from keras.layers.noise import AlphaDropout\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cnn(activation,\n",
    "              dropout_rate):\n",
    "    model = Sequential()\n",
    "    \n",
    "    if(activation == 'selu'):\n",
    "        model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                  activation=activation,\n",
    "                  input_shape=(299, 299, 3),\n",
    "                  kernel_initializer='lecun_normal'))\n",
    "        model.add(Conv2D(64, (3, 3), activation=activation, \n",
    "                         kernel_initializer='lecun_normal'))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(AlphaDropout(0.25))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(128, activation=activation, \n",
    "                        kernel_initializer='lecun_normal'))\n",
    "        model.add(AlphaDropout(0.5))\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "    else:\n",
    "        model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                  activation=activation,\n",
    "                  input_shape=input_shape))\n",
    "        model.add(Conv2D(64, (3, 3), activation=activation))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(128, activation=activation))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    model.compile(optimizer=Adam(learning_rate=1e-4),\n",
    "          loss='binary_crossentropy',\n",
    "          metrics=['acc', 'Precision', 'Recall', 'AUC'])\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 297, 297, 32)      896       \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 295, 295, 64)      18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 147, 147, 64)      0         \n",
      "_________________________________________________________________\n",
      "alpha_dropout_4 (AlphaDropou (None, 147, 147, 64)      0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 1382976)           0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               177021056 \n",
      "_________________________________________________________________\n",
      "alpha_dropout_5 (AlphaDropou (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 177,040,577\n",
      "Trainable params: 177,040,577\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/device:GPU:1'):\n",
    "    model = build_cnn('selu',0.5)\n",
    "\n",
    "    model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"inception_v3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 299, 299, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 149, 149, 32) 864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 149, 149, 32) 96          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 149, 149, 32) 0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 147, 147, 32) 9216        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 147, 147, 32) 96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 147, 147, 32) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 147, 147, 64) 18432       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 147, 147, 64) 192         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 147, 147, 64) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 73, 73, 64)   0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 73, 73, 80)   5120        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 73, 73, 80)   240         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 73, 73, 80)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 71, 71, 192)  138240      activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 71, 71, 192)  576         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 71, 71, 192)  0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 35, 35, 192)  0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 35, 35, 64)   12288       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 35, 35, 64)   192         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 35, 35, 64)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 35, 35, 48)   9216        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 35, 35, 96)   55296       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 35, 35, 48)   144         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 35, 35, 96)   288         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 35, 35, 48)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 35, 35, 96)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 35, 35, 192)  0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 35, 35, 64)   12288       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 35, 35, 64)   76800       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 35, 35, 96)   82944       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 35, 35, 32)   6144        average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 35, 35, 64)   192         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 35, 35, 64)   192         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 35, 35, 96)   288         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 35, 35, 32)   96          conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 35, 35, 64)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 35, 35, 64)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 35, 35, 96)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 35, 35, 32)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 35, 35, 256)  0           activation_5[0][0]               \n",
      "                                                                 activation_7[0][0]               \n",
      "                                                                 activation_10[0][0]              \n",
      "                                                                 activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 35, 35, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 35, 35, 64)   192         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 35, 35, 64)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 35, 35, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 35, 35, 96)   55296       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 35, 35, 48)   144         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 35, 35, 96)   288         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 35, 35, 48)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 35, 35, 96)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 35, 35, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 35, 35, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 35, 35, 64)   76800       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 35, 35, 96)   82944       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 35, 35, 64)   16384       average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 35, 35, 64)   192         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 35, 35, 64)   192         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 35, 35, 96)   288         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 35, 35, 64)   192         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 35, 35, 64)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 35, 35, 64)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 35, 35, 96)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 35, 35, 64)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 35, 35, 288)  0           activation_12[0][0]              \n",
      "                                                                 activation_14[0][0]              \n",
      "                                                                 activation_17[0][0]              \n",
      "                                                                 activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 35, 35, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 35, 35, 64)   192         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 35, 35, 64)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 35, 35, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 35, 35, 96)   55296       activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 35, 35, 48)   144         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 35, 35, 96)   288         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 35, 35, 48)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 35, 35, 96)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 35, 35, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 35, 35, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 35, 35, 64)   76800       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 35, 35, 96)   82944       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 35, 35, 64)   18432       average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 35, 35, 64)   192         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 35, 35, 64)   192         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 35, 35, 96)   288         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 35, 35, 64)   192         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 35, 35, 64)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 35, 35, 64)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 35, 35, 96)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 35, 35, 64)   0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 35, 35, 288)  0           activation_19[0][0]              \n",
      "                                                                 activation_21[0][0]              \n",
      "                                                                 activation_24[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 35, 35, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 35, 35, 64)   192         conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 35, 35, 64)   0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 35, 35, 96)   55296       activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 35, 35, 96)   288         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 35, 35, 96)   0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 17, 17, 384)  995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 17, 17, 96)   82944       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 17, 17, 384)  1152        conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 17, 17, 96)   288         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 17, 17, 384)  0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 17, 17, 96)   0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 17, 17, 288)  0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 17, 17, 768)  0           activation_26[0][0]              \n",
      "                                                                 activation_29[0][0]              \n",
      "                                                                 max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 17, 17, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 17, 17, 128)  384         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 17, 17, 128)  0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 17, 17, 128)  114688      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 17, 17, 128)  384         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 17, 17, 128)  0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 17, 17, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 17, 17, 128)  114688      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 17, 17, 128)  384         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 17, 17, 128)  384         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 17, 17, 128)  0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 17, 17, 128)  0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 17, 17, 128)  114688      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 17, 17, 128)  114688      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 17, 17, 128)  384         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 17, 17, 128)  384         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 17, 17, 128)  0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 17, 17, 128)  0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 17, 17, 768)  0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 17, 17, 192)  147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 17, 17, 192)  172032      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 17, 17, 192)  172032      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 17, 17, 192)  576         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 17, 17, 192)  576         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 17, 17, 192)  576         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 17, 17, 192)  576         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 17, 17, 192)  0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 17, 17, 192)  0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 17, 17, 192)  0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 17, 17, 192)  0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 17, 17, 768)  0           activation_30[0][0]              \n",
      "                                                                 activation_33[0][0]              \n",
      "                                                                 activation_38[0][0]              \n",
      "                                                                 activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 17, 17, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 17, 17, 160)  480         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 17, 17, 160)  0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 17, 17, 160)  179200      activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 17, 17, 160)  480         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 17, 17, 160)  0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 17, 17, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 17, 17, 160)  179200      activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 17, 17, 160)  480         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 17, 17, 160)  480         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 17, 17, 160)  0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 17, 17, 160)  0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 17, 17, 160)  179200      activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 17, 17, 160)  179200      activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 17, 17, 160)  480         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 17, 17, 160)  480         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 17, 17, 160)  0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 17, 17, 160)  0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 17, 17, 768)  0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 17, 17, 192)  147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 17, 17, 192)  215040      activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 17, 17, 192)  215040      activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 17, 17, 192)  576         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 17, 17, 192)  576         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 17, 17, 192)  576         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 17, 17, 192)  576         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 17, 17, 192)  0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 17, 17, 192)  0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 17, 17, 192)  0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 17, 17, 192)  0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 17, 17, 768)  0           activation_40[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "                                                                 activation_48[0][0]              \n",
      "                                                                 activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 17, 17, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 17, 17, 160)  480         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 17, 17, 160)  0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 17, 17, 160)  179200      activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 17, 17, 160)  480         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 17, 17, 160)  0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 17, 17, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 17, 17, 160)  179200      activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 17, 17, 160)  480         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 17, 17, 160)  480         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 17, 17, 160)  0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 17, 17, 160)  0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 17, 17, 160)  179200      activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 17, 17, 160)  179200      activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 17, 17, 160)  480         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 17, 17, 160)  480         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 17, 17, 160)  0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 17, 17, 160)  0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, 17, 17, 768)  0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 17, 17, 192)  147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 17, 17, 192)  215040      activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 17, 17, 192)  215040      activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 17, 17, 192)  576         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 17, 17, 192)  576         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 17, 17, 192)  576         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 17, 17, 192)  576         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 17, 17, 192)  0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 17, 17, 192)  0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 17, 17, 192)  0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 17, 17, 192)  0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 17, 17, 768)  0           activation_50[0][0]              \n",
      "                                                                 activation_53[0][0]              \n",
      "                                                                 activation_58[0][0]              \n",
      "                                                                 activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 17, 17, 192)  576         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 17, 17, 192)  0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 17, 17, 192)  258048      activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 17, 17, 192)  576         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 17, 17, 192)  0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 17, 17, 192)  258048      activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 17, 17, 192)  576         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 17, 17, 192)  576         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 17, 17, 192)  0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 17, 17, 192)  0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 17, 17, 192)  258048      activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 17, 17, 192)  258048      activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 17, 17, 192)  576         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 17, 17, 192)  576         conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 17, 17, 192)  0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 17, 17, 192)  0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePoo (None, 17, 17, 768)  0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 17, 17, 192)  258048      activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 17, 17, 192)  258048      activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 17, 17, 192)  576         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 17, 17, 192)  576         conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 17, 17, 192)  576         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 17, 17, 192)  576         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 17, 17, 192)  0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 17, 17, 192)  0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 17, 17, 192)  0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 17, 17, 192)  0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 17, 17, 768)  0           activation_60[0][0]              \n",
      "                                                                 activation_63[0][0]              \n",
      "                                                                 activation_68[0][0]              \n",
      "                                                                 activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 17, 17, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 17, 17, 192)  576         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 17, 17, 192)  0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 17, 17, 192)  258048      activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 17, 17, 192)  576         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 17, 17, 192)  0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 17, 17, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 17, 17, 192)  258048      activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 17, 17, 192)  576         conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 17, 17, 192)  576         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 17, 17, 192)  0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 17, 17, 192)  0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 8, 8, 320)    552960      activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 8, 8, 192)    331776      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 8, 8, 320)    960         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 8, 8, 192)    576         conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 8, 8, 320)    0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 8, 8, 192)    0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 8, 8, 768)    0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, 8, 8, 1280)   0           activation_71[0][0]              \n",
      "                                                                 activation_75[0][0]              \n",
      "                                                                 max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 8, 8, 448)    573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 8, 8, 448)    1344        conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 8, 8, 448)    0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 8, 8, 384)    491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 8, 8, 384)    1548288     activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 8, 8, 384)    1152        conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 8, 8, 384)    1152        conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 8, 8, 384)    0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 8, 8, 384)    0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 8, 8, 384)    442368      activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 8, 8, 384)    442368      activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 8, 8, 384)    442368      activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 8, 8, 384)    442368      activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_7 (AveragePoo (None, 8, 8, 1280)   0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 8, 8, 320)    409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 8, 8, 384)    1152        conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 8, 8, 384)    1152        conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 8, 8, 384)    1152        conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 8, 8, 384)    1152        conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 8, 8, 192)    245760      average_pooling2d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 8, 8, 320)    960         conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 8, 8, 384)    0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 8, 8, 384)    0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 8, 8, 384)    0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 8, 8, 384)    0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 8, 8, 192)    576         conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 8, 8, 320)    0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, 8, 8, 768)    0           activation_78[0][0]              \n",
      "                                                                 activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 8, 8, 768)    0           activation_82[0][0]              \n",
      "                                                                 activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 8, 8, 192)    0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, 8, 8, 2048)   0           activation_76[0][0]              \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate[0][0]                \n",
      "                                                                 activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 8, 8, 448)    917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 8, 8, 448)    1344        conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 8, 8, 448)    0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 8, 8, 384)    786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 8, 8, 384)    1548288     activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 8, 8, 384)    1152        conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 8, 8, 384)    1152        conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 8, 8, 384)    0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 8, 8, 384)    0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 8, 8, 384)    442368      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 8, 8, 384)    442368      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 8, 8, 384)    442368      activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 8, 8, 384)    442368      activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_8 (AveragePoo (None, 8, 8, 2048)   0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 8, 8, 320)    655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 8, 8, 384)    1152        conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 8, 8, 384)    1152        conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 8, 8, 384)    1152        conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 8, 8, 384)    1152        conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 8, 8, 192)    393216      average_pooling2d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 8, 8, 320)    960         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 8, 8, 384)    0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 8, 8, 384)    0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 8, 8, 384)    0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 8, 8, 384)    0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 8, 8, 192)    576         conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 8, 8, 320)    0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, 8, 8, 768)    0           activation_87[0][0]              \n",
      "                                                                 activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 8, 8, 768)    0           activation_91[0][0]              \n",
      "                                                                 activation_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 8, 8, 192)    0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, 8, 8, 2048)   0           activation_85[0][0]              \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_1[0][0]              \n",
      "                                                                 activation_93[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 21,802,784\n",
      "Trainable params: 21,768,352\n",
      "Non-trainable params: 34,432\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inception_v3 (Model)         (None, 8, 8, 2048)        21802784  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               1049088   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 22,852,385\n",
      "Trainable params: 1,049,601\n",
      "Non-trainable params: 21,802,784\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/device:GPU:1'):\n",
    "    conv_base = InceptionV3(weights='imagenet',\n",
    "                  include_top=False,\n",
    "                  input_shape=(299, 299, 3))\n",
    "\n",
    "    print(conv_base.summary())\n",
    "\n",
    "    conv_base.trainable = False  # Convolution Layer 동결\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(conv_base)\n",
    "\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "    model.add(Dropout(rate=0.5))\n",
    "    model.add(Dense(units=512, activation='relu'))\n",
    "    model.add(Dense(units=1, activation='sigmoid'))\n",
    "    print(model.summary())\n",
    "\n",
    "# with tf.device('/device:GPU:1'):\n",
    "#     model = Sequential()\n",
    "#     model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(299, 299, 3)))\n",
    "#     model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#     model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "#     model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#     model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu'))\n",
    "#     model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#     model.add(Dropout(rate=0.5))\n",
    "#     model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu'))\n",
    "#     model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#     model.add(Conv2D(filters=256, kernel_size=(3, 3), activation='relu'))\n",
    "#     model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "#     model.add(Flatten())    \n",
    "#     model.add(Dropout(rate=0.5))\n",
    "    \n",
    "#     model.add(Dense(units=512, activation='relu'))\n",
    "#     model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "#     print(model.summary())\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.compile(optimizer=Adam(learning_rate=1e-4),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc', 'Precision', 'Recall', 'AUC'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### model.load_weights(pth.join(model_path, model_chk_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "config={ 'batch_size' : 256,\n",
    "         'buffer_size' : 512 }\n",
    "\n",
    "# train_tfrecord_path = 'data/deepfake/all_train.tfrecords'  \n",
    "# val_tfrecord_path = 'data/deepfake/all_val.tfrecords' \n",
    "train_tfrecord_path = 'data/deepfake/all_train.tfrecords'\n",
    "val_tfrecord_path = 'data/deepfake/all_val.tfrecords'\n",
    "\n",
    "image_feature_description = {\n",
    "    'image_raw': tf.io.FixedLenFeature([], tf.string),\n",
    "    '_label': tf.io.FixedLenFeature([], tf.int64),\n",
    "}\n",
    "\n",
    "def _parse_image_function(example_proto):\n",
    "    return tf.io.parse_single_example(example_proto, image_feature_description)\n",
    "\n",
    "def map_func(target_record):\n",
    "    img = target_record['image_raw']\n",
    "    label = target_record['_label']\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img = tf.dtypes.cast(img, tf.float32)\n",
    "    return img, label\n",
    "\n",
    "def resize_and_crop_func(image, label):\n",
    "    result_image = tf.image.resize(image, (299,299))\n",
    "    return result_image, label\n",
    "\n",
    "def post_process_func(image, label):\n",
    "    image = image / 255\n",
    "#     result_image = my_model_base.preprocess_input(image)\n",
    "#     onehot_label = tf.one_hot(label, depth=config['num_class'])\n",
    "    return image, label\n",
    "\n",
    "\n",
    "dataset = tf.data.TFRecordDataset(train_tfrecord_path, compression_type='GZIP')\n",
    "dataset = dataset.map(_parse_image_function, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "dataset = dataset.map(map_func, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "dataset = dataset.map(resize_and_crop_func, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "dataset = dataset.shuffle(config['buffer_size'])\n",
    "dataset = dataset.batch(config['batch_size'])\n",
    "dataset = dataset.map(post_process_func, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "\n",
    "val_dataset = tf.data.TFRecordDataset(val_tfrecord_path, compression_type='GZIP')\n",
    "val_dataset = val_dataset.map(_parse_image_function, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "val_dataset = val_dataset.map(map_func, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "val_dataset = val_dataset.map(resize_and_crop_func, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "# val_dataset = val_dataset.map(image_aug_func, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "val_dataset = val_dataset.shuffle(config['buffer_size'])\n",
    "val_dataset = val_dataset.batch(config['batch_size'])\n",
    "val_dataset = val_dataset.map(post_process_func, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "# val_dataset = val_dataset.cache()\n",
    "val_dataset = val_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset shapes: ((None, 299, 299, 3), (None,)), types: (tf.float32, tf.int64)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/data_env_TF2/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "745/745 [==============================] - 1096s 1s/step - loss: 0.2202 - acc: 0.9073 - precision: 0.9218 - recall: 0.9520 - auc: 0.9642 - val_loss: 0.1215 - val_acc: 0.9538 - val_precision: 0.9554 - val_recall: 0.9823 - val_auc: 0.9909 - lr: 1.0000e-04\n",
      "Epoch 2/30\n",
      "745/745 [==============================] - 1089s 1s/step - loss: 0.1694 - acc: 0.9301 - precision: 0.9482 - recall: 0.9551 - auc: 0.9782 - val_loss: 0.1002 - val_acc: 0.9647 - val_precision: 0.9748 - val_recall: 0.9767 - val_auc: 0.9935 - lr: 1.0000e-04\n",
      "Epoch 3/30\n",
      "745/745 [==============================] - 1089s 1s/step - loss: 0.1574 - acc: 0.9361 - precision: 0.9528 - recall: 0.9587 - auc: 0.9812 - val_loss: 0.0906 - val_acc: 0.9686 - val_precision: 0.9717 - val_recall: 0.9855 - val_auc: 0.9951 - lr: 1.0000e-04\n",
      "Epoch 4/30\n",
      "745/745 [==============================] - 1090s 1s/step - loss: 0.1476 - acc: 0.9406 - precision: 0.9565 - recall: 0.9613 - auc: 0.9835 - val_loss: 0.0812 - val_acc: 0.9730 - val_precision: 0.9774 - val_recall: 0.9856 - val_auc: 0.9960 - lr: 1.0000e-04\n",
      "Epoch 5/30\n",
      "745/745 [==============================] - 1094s 1s/step - loss: 0.1368 - acc: 0.9450 - precision: 0.9601 - recall: 0.9637 - auc: 0.9858 - val_loss: 0.0733 - val_acc: 0.9763 - val_precision: 0.9882 - val_recall: 0.9791 - val_auc: 0.9969 - lr: 1.0000e-04\n",
      "Epoch 6/30\n",
      "745/745 [==============================] - 1105s 1s/step - loss: 0.1267 - acc: 0.9496 - precision: 0.9632 - recall: 0.9670 - auc: 0.9879 - val_loss: 0.0650 - val_acc: 0.9797 - val_precision: 0.9879 - val_recall: 0.9841 - val_auc: 0.9976 - lr: 1.0000e-04\n",
      "Epoch 7/30\n",
      "745/745 [==============================] - 1110s 1s/step - loss: 0.1173 - acc: 0.9538 - precision: 0.9667 - recall: 0.9692 - auc: 0.9897 - val_loss: 0.0589 - val_acc: 0.9813 - val_precision: 0.9867 - val_recall: 0.9876 - val_auc: 0.9982 - lr: 1.0000e-04\n",
      "Epoch 8/30\n",
      "745/745 [==============================] - 1101s 1s/step - loss: 0.1104 - acc: 0.9567 - precision: 0.9690 - recall: 0.9710 - auc: 0.9908 - val_loss: 0.0557 - val_acc: 0.9820 - val_precision: 0.9933 - val_recall: 0.9819 - val_auc: 0.9985 - lr: 1.0000e-04\n",
      "Epoch 9/30\n",
      "745/745 [==============================] - 1101s 1s/step - loss: 0.1042 - acc: 0.9589 - precision: 0.9709 - recall: 0.9721 - auc: 0.9918 - val_loss: 0.0494 - val_acc: 0.9852 - val_precision: 0.9912 - val_recall: 0.9885 - val_auc: 0.9988 - lr: 1.0000e-04\n",
      "Epoch 10/30\n",
      "745/745 [==============================] - 1099s 1s/step - loss: 0.0988 - acc: 0.9615 - precision: 0.9727 - recall: 0.9739 - auc: 0.9926 - val_loss: 0.0469 - val_acc: 0.9851 - val_precision: 0.9947 - val_recall: 0.9847 - val_auc: 0.9990 - lr: 1.0000e-04\n",
      "Epoch 11/30\n",
      "745/745 [==============================] - 1100s 1s/step - loss: 0.0948 - acc: 0.9628 - precision: 0.9739 - recall: 0.9745 - auc: 0.9931 - val_loss: 0.0422 - val_acc: 0.9875 - val_precision: 0.9931 - val_recall: 0.9897 - val_auc: 0.9992 - lr: 1.0000e-04\n",
      "Epoch 12/30\n",
      "745/745 [==============================] - 1100s 1s/step - loss: 0.0908 - acc: 0.9649 - precision: 0.9751 - recall: 0.9762 - auc: 0.9937 - val_loss: 0.0410 - val_acc: 0.9882 - val_precision: 0.9965 - val_recall: 0.9872 - val_auc: 0.9993 - lr: 1.0000e-04\n",
      "Epoch 13/30\n",
      "745/745 [==============================] - 1102s 1s/step - loss: 0.0864 - acc: 0.9664 - precision: 0.9768 - recall: 0.9766 - auc: 0.9943 - val_loss: 0.0382 - val_acc: 0.9896 - val_precision: 0.9960 - val_recall: 0.9897 - val_auc: 0.9994 - lr: 1.0000e-04\n",
      "Epoch 14/30\n",
      "745/745 [==============================] - 1100s 1s/step - loss: 0.0841 - acc: 0.9678 - precision: 0.9774 - recall: 0.9778 - auc: 0.9945 - val_loss: 0.0360 - val_acc: 0.9905 - val_precision: 0.9933 - val_recall: 0.9936 - val_auc: 0.9995 - lr: 1.0000e-04\n",
      "Epoch 15/30\n",
      "745/745 [==============================] - 1098s 1s/step - loss: 0.0806 - acc: 0.9692 - precision: 0.9787 - recall: 0.9785 - auc: 0.9950 - val_loss: 0.0330 - val_acc: 0.9917 - val_precision: 0.9959 - val_recall: 0.9927 - val_auc: 0.9995 - lr: 1.0000e-04\n",
      "Epoch 16/30\n",
      "745/745 [==============================] - 1095s 1s/step - loss: 0.0795 - acc: 0.9692 - precision: 0.9783 - recall: 0.9789 - auc: 0.9951 - val_loss: 0.0335 - val_acc: 0.9912 - val_precision: 0.9972 - val_recall: 0.9907 - val_auc: 0.9996 - lr: 1.0000e-04\n",
      "Epoch 17/30\n",
      "745/745 [==============================] - 1092s 1s/step - loss: 0.0759 - acc: 0.9708 - precision: 0.9795 - recall: 0.9799 - auc: 0.9955 - val_loss: 0.0311 - val_acc: 0.9916 - val_precision: 0.9968 - val_recall: 0.9917 - val_auc: 0.9996 - lr: 1.0000e-04\n",
      "Epoch 18/30\n",
      "745/745 [==============================] - 1088s 1s/step - loss: 0.0752 - acc: 0.9712 - precision: 0.9797 - recall: 0.9802 - auc: 0.9956 - val_loss: 0.0295 - val_acc: 0.9926 - val_precision: 0.9964 - val_recall: 0.9933 - val_auc: 0.9997 - lr: 1.0000e-04\n",
      "Epoch 19/30\n",
      "745/745 [==============================] - 1095s 1s/step - loss: 0.0722 - acc: 0.9723 - precision: 0.9808 - recall: 0.9807 - auc: 0.9960 - val_loss: 0.0277 - val_acc: 0.9930 - val_precision: 0.9966 - val_recall: 0.9939 - val_auc: 0.9997 - lr: 1.0000e-04\n",
      "Epoch 20/30\n",
      "745/745 [==============================] - 1094s 1s/step - loss: 0.0717 - acc: 0.9728 - precision: 0.9812 - recall: 0.9810 - auc: 0.9959 - val_loss: 0.0277 - val_acc: 0.9927 - val_precision: 0.9973 - val_recall: 0.9927 - val_auc: 0.9997 - lr: 1.0000e-04\n",
      "Epoch 21/30\n",
      "745/745 [==============================] - 1094s 1s/step - loss: 0.0693 - acc: 0.9736 - precision: 0.9818 - recall: 0.9815 - auc: 0.9961 - val_loss: 0.0292 - val_acc: 0.9916 - val_precision: 0.9988 - val_recall: 0.9897 - val_auc: 0.9997 - lr: 1.0000e-04\n",
      "Epoch 22/30\n",
      "745/745 [==============================] - 1090s 1s/step - loss: 0.0690 - acc: 0.9736 - precision: 0.9816 - recall: 0.9817 - auc: 0.9962 - val_loss: 0.0273 - val_acc: 0.9922 - val_precision: 0.9982 - val_recall: 0.9911 - val_auc: 0.9998 - lr: 1.0000e-04\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/device:GPU:1'):\n",
    "    history = model.fit(dataset,\n",
    "#                         steps_per_epoch=2000,  #  batch_size * steps_per_epoch이 train데이타의 양보다 크면 안됨!!!!!\n",
    "                        epochs=30,\n",
    "                        validation_data=val_dataset,\n",
    "                        callbacks=callbacks_list,\n",
    "                        validation_steps=50)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(save_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'acc', 'precision', 'recall', 'auc', 'val_loss', 'val_acc', 'val_precision', 'val_recall', 'val_auc', 'lr'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "% matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train_acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "print(history.history.keys())\n",
    "plt.plot(history.history['acc'], 'bo', color='r', label='train_acc')\n",
    "plt.plot(history.history['val_acc'], 'b', color='b', label='val_acc')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.plot(history.history['loss'], 'bo', color='r', label='train_loss')\n",
    "plt.plot(history.history['val_loss'], 'b', color='b', label='val_loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기학습 된 모델 불러오기\n",
    "model = tf.keras.models.load_model('./deepfake_sampling_model_1111.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4100\n",
      "----------------------------------------------------------------------\n",
      "Step 1/ 205\n",
      "Step 2/ 205\n",
      "Step 3/ 205\n",
      "Step 4/ 205\n",
      "Step 5/ 205\n",
      "Step 6/ 205\n",
      "Step 7/ 205\n",
      "Step 8/ 205\n",
      "Step 9/ 205\n",
      "Step 10/ 205\n",
      "Step 11/ 205\n",
      "Step 12/ 205\n",
      "Step 13/ 205\n",
      "Step 14/ 205\n",
      "Step 15/ 205\n",
      "Step 16/ 205\n",
      "Step 17/ 205\n",
      "Step 18/ 205\n",
      "Step 19/ 205\n",
      "Step 20/ 205\n",
      "Step 21/ 205\n",
      "Step 22/ 205\n",
      "Step 23/ 205\n",
      "Step 24/ 205\n",
      "Step 25/ 205\n",
      "Step 26/ 205\n",
      "Step 27/ 205\n",
      "Step 28/ 205\n",
      "Step 29/ 205\n",
      "Step 30/ 205\n",
      "Step 31/ 205\n",
      "Step 32/ 205\n",
      "Step 33/ 205\n",
      "Step 34/ 205\n",
      "Step 35/ 205\n",
      "Step 36/ 205\n",
      "Step 37/ 205\n",
      "Step 38/ 205\n",
      "Step 39/ 205\n",
      "Step 40/ 205\n",
      "Step 41/ 205\n",
      "Step 42/ 205\n",
      "Step 43/ 205\n",
      "Step 44/ 205\n",
      "Step 45/ 205\n",
      "Step 46/ 205\n",
      "Step 47/ 205\n",
      "Step 48/ 205\n",
      "Step 49/ 205\n",
      "Step 50/ 205\n",
      "Step 51/ 205\n",
      "Step 52/ 205\n",
      "Step 53/ 205\n",
      "Step 54/ 205\n",
      "Step 55/ 205\n",
      "Step 56/ 205\n",
      "Step 57/ 205\n",
      "Step 58/ 205\n",
      "Step 59/ 205\n",
      "Step 60/ 205\n",
      "Step 61/ 205\n",
      "Step 62/ 205\n",
      "Step 63/ 205\n",
      "Step 64/ 205\n",
      "Step 65/ 205\n",
      "Step 66/ 205\n",
      "Step 67/ 205\n",
      "Step 68/ 205\n",
      "Step 69/ 205\n",
      "Step 70/ 205\n",
      "Step 71/ 205\n",
      "Step 72/ 205\n",
      "Step 73/ 205\n",
      "Step 74/ 205\n",
      "Step 75/ 205\n",
      "Step 76/ 205\n",
      "Step 77/ 205\n",
      "Step 78/ 205\n",
      "Step 79/ 205\n",
      "Step 80/ 205\n",
      "Step 81/ 205\n",
      "Step 82/ 205\n",
      "Step 83/ 205\n",
      "Step 84/ 205\n",
      "Step 85/ 205\n",
      "Step 86/ 205\n",
      "Step 87/ 205\n",
      "Step 88/ 205\n",
      "Step 89/ 205\n",
      "Step 90/ 205\n",
      "Step 91/ 205\n",
      "Step 92/ 205\n",
      "Step 93/ 205\n",
      "Step 94/ 205\n",
      "Step 95/ 205\n",
      "Step 96/ 205\n",
      "Step 97/ 205\n",
      "Step 98/ 205\n",
      "Step 99/ 205\n",
      "Step 100/ 205\n",
      "Step 101/ 205\n",
      "Step 102/ 205\n",
      "Step 103/ 205\n",
      "Step 104/ 205\n",
      "Step 105/ 205\n",
      "Step 106/ 205\n",
      "Step 107/ 205\n",
      "Step 108/ 205\n",
      "Step 109/ 205\n",
      "Step 110/ 205\n",
      "Step 111/ 205\n",
      "Step 112/ 205\n",
      "Step 113/ 205\n",
      "Step 114/ 205\n",
      "Step 115/ 205\n",
      "Step 116/ 205\n",
      "Step 117/ 205\n",
      "Step 118/ 205\n",
      "Step 119/ 205\n",
      "Step 120/ 205\n",
      "Step 121/ 205\n",
      "Step 122/ 205\n",
      "Step 123/ 205\n",
      "Step 124/ 205\n",
      "Step 125/ 205\n",
      "Step 126/ 205\n",
      "Step 127/ 205\n",
      "Step 128/ 205\n",
      "Step 129/ 205\n",
      "Step 130/ 205\n",
      "Step 131/ 205\n",
      "Step 132/ 205\n",
      "Step 133/ 205\n",
      "Step 134/ 205\n",
      "Step 135/ 205\n",
      "Step 136/ 205\n",
      "Step 137/ 205\n",
      "Step 138/ 205\n",
      "Step 139/ 205\n",
      "Step 140/ 205\n",
      "Step 141/ 205\n",
      "Step 142/ 205\n",
      "Step 143/ 205\n",
      "Step 144/ 205\n",
      "Step 145/ 205\n",
      "Step 146/ 205\n",
      "Step 147/ 205\n",
      "Step 148/ 205\n",
      "Step 149/ 205\n",
      "Step 150/ 205\n",
      "Step 151/ 205\n",
      "Step 152/ 205\n",
      "Step 153/ 205\n",
      "Step 154/ 205\n",
      "Step 155/ 205\n",
      "Step 156/ 205\n",
      "Step 157/ 205\n",
      "Step 158/ 205\n",
      "Step 159/ 205\n",
      "Step 160/ 205\n",
      "Step 161/ 205\n",
      "Step 162/ 205\n",
      "Step 163/ 205\n",
      "Step 164/ 205\n",
      "Step 165/ 205\n",
      "Step 166/ 205\n",
      "Step 167/ 205\n",
      "Step 168/ 205\n",
      "Step 169/ 205\n",
      "Step 170/ 205\n",
      "Step 171/ 205\n",
      "Step 172/ 205\n",
      "Step 173/ 205\n",
      "Step 174/ 205\n",
      "Step 175/ 205\n",
      "Step 176/ 205\n",
      "Step 177/ 205\n",
      "Step 178/ 205\n",
      "Step 179/ 205\n",
      "Step 180/ 205\n",
      "Step 181/ 205\n",
      "Step 182/ 205\n",
      "Step 183/ 205\n",
      "Step 184/ 205\n",
      "Step 185/ 205\n",
      "Step 186/ 205\n",
      "Step 187/ 205\n",
      "Step 188/ 205\n",
      "Step 189/ 205\n",
      "Step 190/ 205\n",
      "Step 191/ 205\n",
      "Step 192/ 205\n",
      "Step 193/ 205\n",
      "Step 194/ 205\n",
      "Step 195/ 205\n",
      "Step 196/ 205\n",
      "Step 197/ 205\n",
      "Step 198/ 205\n",
      "Step 199/ 205\n",
      "Step 200/ 205\n",
      "Step 201/ 205\n",
      "Step 202/ 205\n",
      "Step 203/ 205\n",
      "Step 204/ 205\n",
      "Step 205/ 205\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "path_test = '/home/lab22/data/project_deepfake/test/test_600x600/'\n",
    "df = pd.read_csv('./data/deepfake/sample_submission.csv') \n",
    "\n",
    "\n",
    "id_list = df.iloc[:,0].values \n",
    "print(len(id_list))\n",
    "\n",
    "id_list=[path_test + num for num in id_list]\n",
    "\n",
    "image_w = 299 \n",
    "image_h = 299 \n",
    " \n",
    "test_img_arr = [] \n",
    "prediction=[]\n",
    "batch_size=20                     \n",
    "steps=len(id_list)//batch_size\n",
    "print('-'*70)\n",
    "\n",
    "def score(s):\n",
    "    if s >= 0.5:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "# print(prediction)\n",
    "detector = MTCNN()\n",
    "\n",
    "for e in range(steps):\n",
    "    for i, f in enumerate(id_list[e*batch_size:(e+1)*batch_size]): \n",
    "        img = Image.open(f) \n",
    "        # print(f)\n",
    "        # img = cv2.cvtColor(cv2.imread(f), cv2.COLOR_BGR2RGB)\n",
    "        img = img.convert(\"RGB\") \n",
    "        img = img.resize((image_w, image_h)) \n",
    "        # print(img.shape)\n",
    "        data = np.asarray(img)\n",
    "        data = data/255                # rescale\n",
    "        test_img_arr.append(data)  \n",
    "\n",
    "    test_img_arr = np.array(test_img_arr)               \n",
    "    result = model.predict(test_img_arr)\n",
    "    pred = [score(s) for s in result]\n",
    "    prediction.append(pred)    \n",
    "    test_img_arr = []\n",
    "    print(f'Step {e+1}/ {steps}', end='\\n')\n",
    "print('-'*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>leaderboard/image_00000.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>leaderboard/image_00001.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>leaderboard/image_00002.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>leaderboard/image_00003.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>leaderboard/image_00004.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4095</th>\n",
       "      <td>leaderboard/image_04095.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4096</th>\n",
       "      <td>leaderboard/image_04096.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4097</th>\n",
       "      <td>leaderboard/image_04097.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4098</th>\n",
       "      <td>leaderboard/image_04098.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4099</th>\n",
       "      <td>leaderboard/image_04099.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             path  y\n",
       "0     leaderboard/image_00000.jpg  0\n",
       "1     leaderboard/image_00001.jpg  0\n",
       "2     leaderboard/image_00002.jpg  0\n",
       "3     leaderboard/image_00003.jpg  1\n",
       "4     leaderboard/image_00004.jpg  1\n",
       "...                           ... ..\n",
       "4095  leaderboard/image_04095.jpg  0\n",
       "4096  leaderboard/image_04096.jpg  1\n",
       "4097  leaderboard/image_04097.jpg  0\n",
       "4098  leaderboard/image_04098.jpg  0\n",
       "4099  leaderboard/image_04099.jpg  1\n",
       "\n",
       "[4100 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 제출파일 생성\n",
    "\n",
    "df = pd.DataFrame({'path': df.iloc[:,0].values, \n",
    "                   'y': np.array(prediction).ravel()}, \n",
    "                    columns = ['path','y']) \n",
    "\n",
    "display(df) \n",
    "\n",
    "df.to_csv (r'./data/deepfake/sample_submisstion_1113_02.csv', index = False, header=True) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:data_env_TF2] *",
   "language": "python",
   "name": "conda-env-data_env_TF2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
