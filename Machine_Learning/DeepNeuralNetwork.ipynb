{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"DeepNeuralNetwork.ipynb","provenance":[],"private_outputs":true,"mount_file_id":"1ITmD7v9a-MjRhUCqajOP_OVEyd7Kldwm","authorship_tag":"ABX9TyPfrLsJAqY4R4IA31HbukYS"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"BAmfzaxVu9qJ"},"source":["# XOR\n","import numpy as np\n","import pandas as pd \n","from sklearn.neighbors import KNeighborsRegressor\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Flatten, Dense\n","from tensorflow.keras.optimizers import SGD\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import classification_report\n","from scipy import stats\n","\n","print(tf.__version__)\n","\n","# Training Data Set\n","x_data = np.array([[0,0],\n","                   [0,1],\n","                   [1,0],\n","                   [1,1]], dtype=np.float32)\n","\n","t_data = np.array([[0],[1],[1],[0]], dtype=np.float32)\n","\n","model = Sequential()\n","# model.add(Flatten(input_shape=(2,)))\n","model.add(Dense(100, activation='sigmoid', input_shape=(2,))) # 이렇게 쓰면 윗줄이랑 합체 가능함 # 일반적으로는 Flatten 안씀\n","model.add(Dense(6, activation='sigmoid'))\n","model.add(Dense(1, activation='sigmoid'))\n","\n","model.compile(optimizer=SGD(learning_rate=1e-1), \n","              loss='binary_crossentropy', \n","              metrics=['accuracy'])\n","\n","history = model.fit(x_data, \n","                    t_data, \n","                    epochs=30000, \n","                    verbose=0)\n","\n","predict_val = model.predict(x_data)\n","result = tf.cast(predict_val >= 0.5, dtype=tf.float32).numpy().ravel()\n","\n","\n","print(classification_report(t_data.ravel(),result))\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PbbzBt786n_I"},"source":["print(history.history.keys())\n","\n","plt.plot(history.history['accuracy'], color='b')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Hl5dTgRocssu"},"source":["#### mnist DNN tensorflow2\n","\n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","from sklearn.preprocessing import MinMaxScaler        # Normalization\n","from sklearn.model_selection import train_test_split  # train, test 분리\n","from sklearn.metrics import classification_report\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Dropout\n","from tensorflow.keras.optimizers import Adam\n","\n","# Raw Data Loading\n","df = pd.read_csv('/content/drive/My Drive/MachineLearning/data/mnist/train.csv')\n","display(df.head(), df.shape)\n","\n","##### 결측치와 이상치는 없음 #####\n","\n","# Data Split\n","x_data_train, x_data_test, t_data_train, t_data_test = \\\n","train_test_split(df.drop('label', axis=1, inplace=False), df['label'], test_size=0.3, random_state=0)\n","# test_size : test set의 비율 (0.3 => 30%)\n","# random_state : split할 때 랜덤하게 split하게 되는데 이를 일정하게 고정(seed의 개념)\n","\n","# Min-Max Normalization\n","scaler = MinMaxScaler()   # scaler = StandardScaler()\n","scaler.fit(x_data_train)\n","x_data_train_norm = scaler.transform(x_data_train)\n","x_data_test_norm = scaler.transform(x_data_test)\n","\n","del x_data_train\n","del x_data_test\n","\n","## TF2.1 구현\n","\n","model = Sequential()\n","\n","model.add(Dense(256, \n","                activation='relu', \n","                kernel_initializer='he_uniform',\n","                input_shape=(x_data_train_norm.shape[1],))\n","          )\n","model.add(Dropout(0.3))\n","model.add(Dense(128, \n","                activation='relu', \n","                kernel_initializer='he_uniform'))\n","model.add(Dropout(0.3))\n","model.add(Dense(10, \n","                activation='softmax', \n","                kernel_initializer='he_uniform'))\n","\n","model.compile(optimizer=Adam(learning_rate=1e-3),\n","             loss='sparse_categorical_crossentropy',\n","             metrics=['sparse_categorical_accuracy'])\n","\n","history = model.fit(x_data_train_norm,\n","                    t_data_train,\n","                    epochs=100,\n","                    verbose=1,\n","                    batch_size=128,\n","                    validation_split=0.3)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aN9EBDCUFE1S"},"source":["result = np.argmax(model.predict(x_data_test_norm), axis=1)\n","print(classification_report(t_data_test, result))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YlDdu153FQC6"},"source":["import matplotlib.pyplot as plt\n","\n","print(history.history.keys())\n","plt.plot(history.history['sparse_categorical_accuracy'], color='r')\n","plt.plot(history.history['val_sparse_categorical_accuracy'], color='b')\n","plt.show()"],"execution_count":null,"outputs":[]}]}